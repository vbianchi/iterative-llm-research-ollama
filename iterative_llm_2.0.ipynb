{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Research Question ####\n",
      "\n",
      "use of LLM in bioinformatics\n",
      "\n",
      "\n",
      "#### Initial Explanation ####\n",
      "\n",
      "The integration of Large Language Models (LLMs) in bioinformatics has revolutionized the field by enabling researchers to analyze vast amounts of biological data, identify patterns, and make predictions with unprecedented accuracy. Bioinformatics, which is the application of computational tools and statistical techniques to analyze biological data, relies heavily on LLMs for various tasks such as gene prediction, protein structure prediction, functional annotation, and disease diagnosis.\n",
      "\n",
      "**Applications of LLMs in bioinformatics**\n",
      "\n",
      "1. **Gene Prediction**: LLMs can be trained on large datasets of annotated genes and used to predict the presence or absence of genes in a given sequence. This is particularly useful for annotating genomes of organisms with incomplete or low-quality genomic data.\n",
      "2. **Protein Structure Prediction**: LLMs can be used to predict protein structures from amino acid sequences, which is essential for understanding protein function and identifying potential drug targets.\n",
      "3. **Functional Annotation**: LLMs can analyze genomic and proteomic data to assign functional annotations such as gene function, protein-protein interactions, and regulatory elements.\n",
      "4. **Disease Diagnosis**: LLMs can be trained on large datasets of genomic and transcriptomic data from patients with various diseases, enabling the development of predictive models that can diagnose diseases at an early stage.\n",
      "5. **Sequence Alignment**: LLMs can be used to align sequences and identify conserved regions, which is essential for understanding evolutionary relationships between organisms.\n",
      "\n",
      "**Advantages of using LLMs in bioinformatics**\n",
      "\n",
      "1. **Scalability**: LLMs can analyze large amounts of data quickly, making them ideal for high-throughput sequencing data.\n",
      "2. **Accuracy**: LLMs can achieve higher accuracy than traditional methods in certain tasks such as gene prediction and functional annotation.\n",
      "3. **Speed**: LLMs can process vast amounts of data rapidly, enabling researchers to generate results quickly.\n",
      "\n",
      "**Challenges and limitations**\n",
      "\n",
      "1. **Data Quality**: The performance of LLMs in bioinformatics is heavily dependent on the quality and accuracy of the training data.\n",
      "2. **Domain Adaptation**: LLMs may not generalize well across different domains or organisms, requiring adaptation for specific use cases.\n",
      "3. **Explainability**: The interpretability of LLMs in bioinformatics is a challenge, as it can be difficult to understand the reasoning behind their predictions.\n",
      "4. **Bias**: LLMs may inherit biases present in the training data, which can lead to inaccurate results.\n",
      "\n",
      "**Future directions**\n",
      "\n",
      "1. **Multitask Learning**: Incorporating multiple tasks into a single model to improve performance and efficiency.\n",
      "2. **Transfer Learning**: Using pre-trained models as a starting point for new tasks, reducing the need for large amounts of labeled data.\n",
      "3. **Explainability Techniques**: Developing methods to provide insights into the reasoning behind LLM predictions, such as saliency maps or feature importance scores.\n",
      "4. **Bias Detection and Mitigation**: Implementing techniques to detect and mitigate biases in LLMs, ensuring fair and accurate results.\n",
      "\n",
      "**Gaps in current research**\n",
      "\n",
      "1. **Limited Use of LLMs in Low-Resource Settings**: While LLMs have been widely adopted in high-resource settings, there is a need for more research on their application in low-resource settings where computational resources are limited.\n",
      "2. **Insufficient Exploration of Heterogeneous Data**: Most studies have focused on homogeneous data (e.g., genomic sequences), neglecting the potential benefits of incorporating heterogeneous data (e.g., metagenomic or transcriptomic data).\n",
      "3. **Inadequate Evaluation Metrics**: The use of traditional metrics such as accuracy and precision may not be sufficient to evaluate LLM performance in bioinformatics, where the stakes are high and errors can have significant consequences.\n",
      "4. **Lack of Standardization**: There is a need for standardization in the development and evaluation of LLMs in bioinformatics, ensuring consistency across different studies and applications.\n",
      "\n",
      "In conclusion, LLMs have revolutionized the field of bioinformatics by enabling researchers to analyze vast amounts of biological data with unprecedented accuracy. However, there are still areas that require further exploration, such as the application of LLMs in low-resource settings, the use of heterogeneous data, and the development of explainability techniques. Addressing these gaps will be essential for unlocking the full potential of LLMs in bioinformatics and driving progress in the field.\n",
      "\n",
      "\n",
      "#### Thinking Process ####\n",
      "\n",
      ">> Iteration 1\n",
      "\n",
      "  >> Find gap... \n",
      "     > Follow-up Question: Application of large language models in microbiome analysis\n",
      "     > Web-search query: large language models microbiome analysis\n",
      "  >> Query web-literature... \n",
      "Enhanced Query: large language models microbiome analysis site:pubmed.ncbi.nlm.nih.gov OR site:sciencedirect.com OR site:doi.org peer-reviewed journal\n",
      "  >> Combine literature to assay... \n",
      "The paper discusses the development of a new deep learning model called PLAPD (Protein Language Model for Antimicrobial Peptides Discovery) that uses a combination of local feature extraction via convolutional layers and global feature extraction with a residual Transformer module to predict antimicrobial peptides. The authors benchmarked PLAPD against state-of-the-art models using a dataset of 8,268 peptide sequences and achieved superior performance in accuracy, precision, specificity, MCC (Mean Cumulative Classification), and AUC (Area Under the Curve). \n",
      "\n",
      "The potential of PLAPD as a high-throughput and accurate tool for antimicrobial peptides discovery is highlighted. The study suggests that deep learning models like PLAPD can be used to analyze large volumes of data in microbiome studies and other fields where complex datasets require robust tools based on artificial intelligence.\n",
      "\n",
      "Here are some key points from the paper:\n",
      "\n",
      "1. **PLAPD Model**: PLAPD is a protein language model designed for antimicrobial peptides discovery, combining local feature extraction via convolutional layers and global feature extraction with a residual Transformer module.\n",
      "\n",
      "2. **Dataset**: The authors used a dataset of 8,268 peptide sequences to benchmark their model against state-of-the-art models.\n",
      "\n",
      "3. **Performance Comparison**: PLAPD outperformed other models in terms of accuracy (0.87), precision (0.9359), specificity (0.9456), MCC (0.7486), and AUC (0.9225).\n",
      "\n",
      "4. **Potential Application**: The study suggests that deep learning models like PLAPD can be used to analyze large volumes of data in microbiome studies and other fields where complex datasets require robust tools based on artificial intelligence.\n",
      "\n",
      "Overall, the paper presents a new model for antimicrobial peptides discovery using deep learning techniques and highlights its potential as a high-throughput tool.\n",
      ">> Iteration 2\n",
      "\n",
      "  >> Find gap... \n",
      "     > Follow-up Question: Predictive models for identifying antimicrobial peptides with diverse structures\n",
      "     > Web-search query: predictive models for antimicrobial peptides with diverse structures\n",
      "  >> Query web-literature... \n",
      "Enhanced Query: predictive models for antimicrobial peptides with diverse structures site:pubmed.ncbi.nlm.nih.gov OR site:sciencedirect.com OR site:doi.org peer-reviewed journal\n"
     ]
    },
    {
     "ename": "DuckDuckGoSearchException",
     "evalue": "https://lite.duckduckgo.com/lite/ 202 Ratelimit",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDuckDuckGoSearchException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 290\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;66;03m# # Step 7: Save the final assay locally\u001b[39;00m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;66;03m#     with open(\"final_assay.txt\", \"w\", encoding=\"utf-8\") as f:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# except Exception as e:\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;66;03m#     print(\"Error saving the final assay:\", e)\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 290\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[6], line 255\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  >> Query web-literature... \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    254\u001b[0m user_query \u001b[38;5;241m=\u001b[39m followup_question_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb-query\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 255\u001b[0m web_search \u001b[38;5;241m=\u001b[39m search_scientific_literature(user_query, num_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, fetch_full_page\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    256\u001b[0m \u001b[38;5;66;03m#print(\"\\n--- Search Results ---\")\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m#print(json.dumps(results, indent=2))\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# Step 5: Reiterate on a new topic\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  >> Combine literature to assay... \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 125\u001b[0m, in \u001b[0;36msearch_scientific_literature\u001b[1;34m(query, num_results, fetch_full_page)\u001b[0m\n\u001b[0;32m    123\u001b[0m enhanced_query \u001b[38;5;241m=\u001b[39m enhance_query_for_scientific_literature(query)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnhanced Query:\u001b[39m\u001b[38;5;124m\"\u001b[39m, enhanced_query)\n\u001b[1;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m duckduckgo_search(enhanced_query, max_results\u001b[38;5;241m=\u001b[39mnum_results, fetch_full_page\u001b[38;5;241m=\u001b[39mfetch_full_page)\n",
      "Cell \u001b[1;32mIn[6], line 87\u001b[0m, in \u001b[0;36mduckduckgo_search\u001b[1;34m(query, max_results, fetch_full_page)\u001b[0m\n\u001b[0;32m     85\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m DDGS() \u001b[38;5;28;01mas\u001b[39;00m ddgs:\n\u001b[1;32m---> 87\u001b[0m     search_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ddgs\u001b[38;5;241m.\u001b[39mtext(query, max_results\u001b[38;5;241m=\u001b[39mmax_results))\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m search_results:\n\u001b[0;32m     89\u001b[0m         url \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\valer\\anaconda3\\Lib\\site-packages\\duckduckgo_search\\duckduckgo_search.py:292\u001b[0m, in \u001b[0;36mDDGS.text\u001b[1;34m(self, keywords, region, safesearch, timelimit, backend, max_results)\u001b[0m\n\u001b[0;32m    289\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError to search using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m backend: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    290\u001b[0m         err \u001b[38;5;241m=\u001b[39m ex\n\u001b[1;32m--> 292\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m DuckDuckGoSearchException(err)\n",
      "\u001b[1;31mDuckDuckGoSearchException\u001b[0m: https://lite.duckduckgo.com/lite/ 202 Ratelimit"
     ]
    }
   ],
   "source": [
    "from ollama import chat, ChatResponse\n",
    "import json\n",
    "import re\n",
    "from IPython.display import display, Markdown\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "# --- Prompt Baselines ---\n",
    "RESPONSE_PROMPT = (\n",
    "    \"You are an expert on the topic: {research_topic}. Provide an extensive, detailed, and comprehensive answer \"\n",
    "    \"to the research question. In your answer, highlight any areas or gaps that might require further exploration.\"\n",
    ")\n",
    "\n",
    "FIND_GAP_PROMPT = (\n",
    "    \"You are a group of 3 experts on the topic: {research_topic}.\"\n",
    "    \"Think step by step on the following assay: \"\n",
    "    \"<ASSAY>\"\n",
    "    \"{assay}\"\n",
    "    \"</ASSAY>\"\n",
    "    \"Provide one new topic to explore to fill a knowledge gap in the assay.\"\n",
    "    \"Based on the gaps identified in your answer, generate a JSON object with the following keys:\\n\"\n",
    "    '   - \"query\": \"The search query string.\"\\n'\n",
    "    '   - \"web-query\": \"The web search query string.\"\\n'\n",
    "    '   - \"aspect\": \"The aspect of the topic being addressed by this query.\"\\n'\n",
    "    '   - \"rationale\": \"Why this query will help fill the gap.\"\\n'\n",
    "    \"Provide only the JSON structure.\"\n",
    ")\n",
    "\n",
    "COMBINE_PROMPT = (\n",
    "    \"You are a group of 3 experts on the topic: {research_topic}.\"\n",
    "    \"You have to combine together the information from the written assay in <ASSAY></ASSAY> tags, \"\n",
    "    \"with the information gathered from the results of a web search on peer-reviewed literature within the <WEB></WEB> tags.\"\n",
    "    \"When combining them together you are allowed to use only the sources identified through the web search.\"\n",
    "    \"Cite them in the text where appropriate and report them at the bottom.\"\n",
    "    \"<ASSAY>\"\n",
    "    \"{assay}\"\n",
    "    \"</ASSAY>\"\n",
    "    \"<WEB>\"\n",
    "    \"{web_search}\"\n",
    "    \"</WEB>\"\n",
    ")\n",
    "\n",
    "FINALIZE_RESPONSE_PROMPT = (\n",
    "    \"You are a team of expert on the topic: {research_topic}. Your goal is to analyze the text provided in the <TEXT></TEXT> tags \"\n",
    "    \"and create an extensive, detailed, and comprehensive report using the information provided. Aim to 500 words per section.\"\n",
    "    \"Your thesis is formatted in markdown and have:\\n\"\n",
    "    \"1. Title\\n\"\n",
    "    \"2. Introduction\\n\"\n",
    "    \"3. Discussion\\n\"\n",
    "    \"4. Gaps / Further research\\n\"\n",
    "    \"<TEXT>\"\n",
    "    \"{notes}\"\n",
    "    \"</TEXT>\"\n",
    ")\n",
    "\n",
    "def enhance_query_for_scientific_literature(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Enhance an LLM-generated query to focus on scientific literature by appending \n",
    "    academic-specific filters and keywords.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The original query.\n",
    "        \n",
    "    Returns:\n",
    "        str: The enhanced query.\n",
    "    \"\"\"\n",
    "    # Add filters to restrict results to scientific literature domains and add academic keywords.\n",
    "    filters = \"site:pubmed.ncbi.nlm.nih.gov OR site:sciencedirect.com OR site:doi.org peer-reviewed journal\"\n",
    "    return f\"{query} {filters}\"\n",
    "\n",
    "def duckduckgo_search(query: str, max_results: int = 5, fetch_full_page: bool = False) -> dict:\n",
    "    \"\"\"\n",
    "    Perform a DuckDuckGo search for the given query.\n",
    "    Optionally fetch full page content.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query.\n",
    "        max_results (int): Number of results to return.\n",
    "        fetch_full_page (bool): If True, attempt to retrieve the full page content.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary with a \"results\" key containing a list of result dicts.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    with DDGS() as ddgs:\n",
    "        search_results = list(ddgs.text(query, max_results=max_results))\n",
    "        for r in search_results:\n",
    "            url = r.get(\"href\")\n",
    "            title = r.get(\"title\")\n",
    "            content = r.get(\"body\")\n",
    "            if not all([url, title, content]):\n",
    "                continue\n",
    "            raw_content = content\n",
    "            if fetch_full_page:\n",
    "                try:\n",
    "                    req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "                    response = urllib.request.urlopen(req)\n",
    "                    html = response.read().decode('utf-8', errors='replace')\n",
    "                    raw_content = BeautifulSoup(html, 'html.parser').get_text()\n",
    "                except Exception as e:\n",
    "                    raw_content = content  # fallback to the snippet content\n",
    "            results.append({\n",
    "                \"title\": title,\n",
    "                \"url\": url,\n",
    "                \"content\": content,\n",
    "                \"raw_content\": raw_content\n",
    "            })\n",
    "    return {\"results\": results}\n",
    "\n",
    "def search_scientific_literature(query: str, num_results: int = 5, fetch_full_page: bool = False) -> dict:\n",
    "    \"\"\"\n",
    "    Enhance the given query for scientific literature and perform a DuckDuckGo search.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The original query.\n",
    "        num_results (int): Number of results to return.\n",
    "        fetch_full_page (bool): If True, fetch full page content.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Search results as returned by duckduckgo_search.\n",
    "    \"\"\"\n",
    "    enhanced_query = enhance_query_for_scientific_literature(query)\n",
    "    print(\"Enhanced Query:\", enhanced_query)\n",
    "    return duckduckgo_search(enhanced_query, max_results=num_results, fetch_full_page=fetch_full_page)\n",
    "\n",
    "# --- Helper: Remove <THINK> Tags ---\n",
    "def remove_think_tags(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove any text enclosed in <THINK>...</THINK> tags.\n",
    "    The regex is case-insensitive.\n",
    "    \"\"\"\n",
    "    return re.sub(r\"<\\s*THINK\\s*>.*?<\\s*/\\s*THINK\\s*>\", \"\", text, flags=re.DOTALL | re.IGNORECASE).strip()\n",
    "\n",
    "# --- Configuration & State Management ---\n",
    "class Configuration:\n",
    "    def __init__(self, ollama_base_url: str, local_llm: str, fetch_full_page: bool,\n",
    "                 max_research_loops: int, max_fetch_pages: int, max_token_per_search: int):\n",
    "        self.ollama_base_url = ollama_base_url\n",
    "        self.local_llm = local_llm\n",
    "        self.fetch_full_page = fetch_full_page\n",
    "        self.max_research_loops = max_research_loops\n",
    "        self.max_fetch_pages = max_fetch_pages\n",
    "        self.max_token_per_search = max_token_per_search\n",
    "\n",
    "def query_local_llm(state: dict, config: Configuration, prompt=\"\") -> str:\n",
    "    \"\"\"\n",
    "    Generate an extensive answer for the research topic.\n",
    "    The answer should also indicate potential gaps for further research.\n",
    "    \"\"\"\n",
    "    message = {\"role\": \"user\", \"content\": prompt}\n",
    "    response: ChatResponse = chat(model=config.local_llm, messages=[message])\n",
    "    initial_response = remove_think_tags(response.message.content.strip())\n",
    "    state[\"initial_response\"] = initial_response\n",
    "    state[\"assay\"] = initial_response\n",
    "    return initial_response\n",
    "\n",
    "def initialize_state(research_topic: str) -> dict:\n",
    "    \"\"\"\n",
    "    Initialize the research state with the given topic.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"research_topic\": research_topic,\n",
    "        \"initial_response\": \"\",       # The original extensive answer.\n",
    "        \"assay\":\"\",\n",
    "        \"search_query\": research_topic\n",
    "    }\n",
    "\n",
    "def extract_json_from_llm_output(text: str):\n",
    "    \"\"\"\n",
    "    Attempt to extract a JSON object from the provided text.\n",
    "    This function supports two formats:\n",
    "      1. JSON enclosed in triple backticks with the tag \"json\" (e.g., ```json { ... } ```).\n",
    "      2. JSON enclosed in triple backticks without the tag (e.g., ``` { ... } ```).\n",
    "      3. A plain JSON string.\n",
    "    \n",
    "    Returns:\n",
    "        Parsed JSON object.\n",
    "        \n",
    "    Raises:\n",
    "        ValueError if no valid JSON structure can be found or parsed.\n",
    "    \"\"\"\n",
    "    # Define patterns for JSON enclosed in triple backticks.\n",
    "    patterns = [\n",
    "        r\"```json\\s*(\\{.*?\\})\\s*```\",  # with \"json\" tag (case-insensitive)\n",
    "        r\"```(\\{.*?\\})```\"             # without the tag\n",
    "    ]\n",
    "    \n",
    "    matches = []\n",
    "    for pattern in patterns:\n",
    "        found = re.findall(pattern, text, flags=re.DOTALL | re.IGNORECASE)\n",
    "        if found:\n",
    "            matches.extend(found)\n",
    "    \n",
    "    # If no triple-backtick JSON is found, check if the whole text is JSON.\n",
    "    if not matches:\n",
    "        stripped = text.strip()\n",
    "        if stripped.startswith(\"{\") and stripped.endswith(\"}\"):\n",
    "            matches.append(stripped)\n",
    "    \n",
    "    if not matches:\n",
    "        print(\"<ERROR>:\\n%s\\n</ERROR>\" % text)\n",
    "        raise ValueError(\"No JSON structure found in the provided text.\")\n",
    "    \n",
    "    # Try parsing each candidate.\n",
    "    for match in matches:\n",
    "        try:\n",
    "            json_data = json.loads(match)\n",
    "            return json_data\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "    \n",
    "    print(\"<ERROR>:\\n%s\\n</ERROR>\" % text)\n",
    "    raise ValueError(\"Found JSON-like structure, but could not parse it.\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    config = Configuration(\n",
    "        ollama_base_url=\"http://localhost:11434\",  # Your Ollama URL\n",
    "        local_llm=\"llama3.2\",                      # Default LLM is \"llama3.2\"\n",
    "        fetch_full_page=True,                      # Fetch full page content if needed\n",
    "        max_research_loops=3,                      # Number of research iterations\n",
    "        max_fetch_pages=5,                         # Number of pages to fetch per search\n",
    "        max_token_per_search=4000                  # Token limit per search processing\n",
    "    )\n",
    "\n",
    "    # Step 1: Get the research question from the user\n",
    "    research_topic = input(\"Enter your research question: \")\n",
    "    print(\"#### Research Question ####\\n\")\n",
    "    print(research_topic)\n",
    "    print(\"\\n\")\n",
    "    state = initialize_state(research_topic)\n",
    "\n",
    "    # Step 2: Generate an initial explanation using the local LLM. This answer will be the first instance of the assay\n",
    "    print(\"  >> Create initial assay... \\n\")\n",
    "    prompt_initial = RESPONSE_PROMPT.format(research_topic=state[\"research_topic\"])\n",
    "    initial_explanation = query_local_llm(state, config, prompt_initial)\n",
    "    print(initial_explanation)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"#### Thinking Process ####\\n\")\n",
    "    for i in range(config.max_research_loops):\n",
    "        print(f\">> Iteration {i+1}\\n\")\n",
    "        print(\"  >> Find gap... \")\n",
    "        # Step 3: Evaluate the current assay and generate a follow-up question\n",
    "        prompt_gap = FIND_GAP_PROMPT.format(research_topic=state[\"research_topic\"], assay=state[\"assay\"])\n",
    "        followup_question_llm = query_local_llm(state, config, prompt_gap)\n",
    "        followup_question_json = extract_json_from_llm_output(followup_question_llm)\n",
    "        print(f\"     > Follow-up Question: {followup_question_json[\"query\"]}\")\n",
    "        print(f\"     > Web-search query: {followup_question_json[\"web-query\"]}\")\n",
    "\n",
    "        # Step 4: Gather literature sources\n",
    "        print(\"  >> Query web-literature... \")\n",
    "        user_query = followup_question_json[\"web-query\"]\n",
    "        web_search = search_scientific_literature(user_query, num_results=5, fetch_full_page=True)\n",
    "        #print(\"\\n--- Search Results ---\")\n",
    "        #print(json.dumps(results, indent=2))\n",
    "\n",
    "        # Step 5: Reiterate on a new topic\n",
    "        print(\"  >> Combine literature to assay... \")\n",
    "        prompt_follow = COMBINE_PROMPT.format(research_topic=followup_question_json[\"query\"], assay=state[\"assay\"], web_search=web_search)\n",
    "        follow_explanation = query_local_llm(state, config, prompt_follow)\n",
    "        print(follow_explanation)\n",
    "        #print(\"  >> Generate new response based on follow-up question... \\n\")\n",
    "        # Step 4: Reiterate on a new topic\n",
    "        #prompt_follow = RESPONSE_PROMPT.format(research_topic=followup_question_json[\"query\"])\n",
    "        #follow_explanation = query_local_llm(state, config, prompt_initial)\n",
    "        #print(\"  >> Add new data to notes... \\n\")\n",
    "        # Step 5: Add the data to the assay\n",
    "        state[\"assay\"] =  state[\"assay\"] + follow_explanation\n",
    "\n",
    "    # print(state[\"assay\"])\n",
    "    # Step 6: Ask the LLM to finalize the assay by integrating all gathered information and adding references\n",
    "    prompt_finalize = FINALIZE_RESPONSE_PROMPT.format(research_topic=state[\"research_topic\"], notes=state[\"assay\"] )\n",
    "    finalize_text_llm = query_local_llm(state, config, prompt_finalize)\n",
    "    \n",
    "    print(\"#### Final Assay ####\\n\")\n",
    "    #print(finalize_text_llm)\n",
    "    display(Markdown(finalize_text_llm))\n",
    "\n",
    "    # # Step 7: Save the final assay locally\n",
    "    # try:\n",
    "    #     with open(\"final_assay.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    #         f.write(final_assay)\n",
    "    #     print(\"\\nFinal assay saved to 'final_assay.txt'.\")\n",
    "    # except Exception as e:\n",
    "    #     print(\"Error saving the final assay:\", e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# What is the state of the art of open source LLMs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Research Question ####\n",
      "\n",
      "How to combine quantum physics and bioinformatics\n",
      "\n",
      "\n",
      "  >> Create initial assay...\n",
      "\n",
      "Combining Quantum Physics and Bioinformatics: A Comprehensive Overview\n",
      "\n",
      "Quantum physics has revolutionized our understanding of the fundamental laws governing the behavior of matter and energy at the smallest scales. Similarly, bioinformatics has transformed the way we analyze and interpret biological data. By integrating these two seemingly disparate fields, researchers can uncover new insights into the intricate workings of living systems. This comprehensive review aims to provide an in-depth exploration of the intersections between quantum physics and bioinformatics.\n",
      "\n",
      "**Quantum Physics in Bioinformatics**\n",
      "\n",
      "Bioinformatics is the application of computational tools and statistical methods to analyze and interpret biological data. Quantum physics, on the other hand, provides a framework for understanding the behavior of matter at the atomic and subatomic level. By applying principles from quantum physics to bioinformatics, researchers can develop new analytical tools and models that better capture the complexities of biological systems.\n",
      "\n",
      "**Key Areas of Intersection**\n",
      "\n",
      "1. **Quantum Computing and Genomics**: Quantum computing has the potential to revolutionize genome analysis by enabling the simulation of complex genetic interactions at scales currently unattainable with classical computers. This could lead to breakthroughs in gene expression prediction, gene regulation, and disease modeling.\n",
      "2. **Quantum Biology and Protein Folding**: The principles of quantum physics can be applied to understand protein folding and stability. By simulating protein-ligand interactions using quantum mechanics, researchers may uncover new insights into protein function, binding affinities, and potential therapeutic targets.\n",
      "3. **Quantum Signal Processing in Biological Systems**: Quantum signal processing has been explored in the context of biological systems, such as sensory perception and cognitive processes. Understanding how quantum signals are processed and decoded could reveal novel mechanisms for information transmission and encoding.\n",
      "\n",
      "**Theoretical Frameworks**\n",
      "\n",
      "1. **Quantum Entanglement and Correlation Analysis**: Entanglement is a fundamental concept in quantum physics that describes the interconnectedness of particles. Researchers have proposed using entanglement-based measures to analyze biological correlation patterns, potentially uncovering hidden relationships between genes or proteins.\n",
      "2. **Quantum Information and Machine Learning**: Quantum information theory can be applied to develop new machine learning algorithms for bioinformatics tasks, such as predicting gene expression patterns, identifying biomarkers, or detecting disease-associated mutations.\n",
      "\n",
      "**Methodologies and Tools**\n",
      "\n",
      "1. **Quantum Algorithms for Bioinformatics**: Researchers have developed quantum algorithms specifically designed for bioinformatics applications, including quantum approximation optimization algorithm (QAOA) for optimizing protein-ligand interactions.\n",
      "2. **Machine Learning with Quantum Randomness**: The incorporation of quantum randomness into machine learning algorithms can enhance their ability to capture complex patterns in biological data.\n",
      "\n",
      "**Current Research Gaps and Future Directions**\n",
      "\n",
      "1. **Scalability and Noise Tolerance**: Currently, most quantum computing applications are limited by scalability issues and noise tolerance. Improving these aspects will be crucial for practical application in bioinformatics.\n",
      "2. **Quantum-Classical Interoperability**: The seamless integration of quantum algorithms with classical computational tools is essential for effective problem-solving in bioinformatics.\n",
      "3. **Biological Interpretation and Validation**: Further research is needed to translate the results from quantum computing applications into biologically meaningful insights, ensuring that these findings are validated against empirical data.\n",
      "\n",
      "**Open Research Questions**\n",
      "\n",
      "1. **Quantum Entanglement in Biological Systems**: Can entanglement be observed or harnessed in biological systems?\n",
      "2. **Quantum-Inspired Biomarkers for Disease Detection**: How can quantum-inspired machine learning algorithms be used to develop more accurate biomarkers for disease detection and diagnosis?\n",
      "3. **Synthetic Biology with Quantum Computing**: Can quantum computing be applied to design novel biological pathways, circuits, or gene regulatory networks?\n",
      "\n",
      "**Conclusion**\n",
      "\n",
      "The intersection of quantum physics and bioinformatics holds tremendous potential for revolutionizing our understanding of biological systems. By exploring the theoretical frameworks, methodologies, tools, and current research gaps in this field, researchers can develop innovative solutions that integrate the strengths of both disciplines. The possibilities are vast, ranging from enhancing genome analysis to predicting biomarkers for disease detection.\n",
      "\n",
      "However, further exploration is necessary to address the existing research gaps and overcome the challenges associated with quantum computing applications in bioinformatics. By bridging these knowledge gaps, researchers can unlock new opportunities for understanding the intricate workings of living systems and harnessing their full potential.\n",
      "\n",
      "\n",
      "#### Thinking Process ####\n",
      "\n",
      ">> Iteration 1\n",
      "\n",
      "  >> Find gap...\n",
      "     > Follow-up Question: Quantum entanglement in biological systems\n",
      "     > Web-search query: quantum entanglement in biology research papers\n",
      "  >> Query web-literature...\n",
      "Enhanced Query: quantum entanglement in biology research papers site:pubmed.ncbi.nlm.nih.gov OR site:sciencedirect.com OR site:doi.org peer-reviewed journal\n",
      "Rate limit encountered. Retrying in 2 seconds...\n",
      "Rate limit encountered. Retrying in 4 seconds...\n",
      "Rate limit encountered. Retrying in 8 seconds...\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Exceeded maximum retries due to rate limiting.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 271\u001b[0m\n\u001b[0;32m    268\u001b[0m     display(Markdown(finalize_text_llm))\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 271\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[7], line 253\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  >> Query web-literature...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    252\u001b[0m user_query \u001b[38;5;241m=\u001b[39m followup_question_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb-query\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 253\u001b[0m web_search \u001b[38;5;241m=\u001b[39m search_scientific_literature(user_query, num_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, fetch_full_page\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    255\u001b[0m \u001b[38;5;66;03m# Step 5: Combine literature with the assay.\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  >> Combine literature to assay...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 131\u001b[0m, in \u001b[0;36msearch_scientific_literature\u001b[1;34m(query, num_results, fetch_full_page)\u001b[0m\n\u001b[0;32m    129\u001b[0m enhanced_query \u001b[38;5;241m=\u001b[39m enhance_query_for_scientific_literature(query)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnhanced Query:\u001b[39m\u001b[38;5;124m\"\u001b[39m, enhanced_query)\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m duckduckgo_search(enhanced_query, max_results\u001b[38;5;241m=\u001b[39mnum_results, fetch_full_page\u001b[38;5;241m=\u001b[39mfetch_full_page)\n",
      "Cell \u001b[1;32mIn[7], line 101\u001b[0m, in \u001b[0;36mduckduckgo_search\u001b[1;34m(query, max_results, fetch_full_page, retries, backoff)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExceeded maximum retries due to rate limiting.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: Exceeded maximum retries due to rate limiting."
     ]
    }
   ],
   "source": [
    "from ollama import chat, ChatResponse\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import urllib.request\n",
    "import datetime\n",
    "from IPython.display import display, Markdown\n",
    "from bs4 import BeautifulSoup\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "# --- Prompt Baselines ---\n",
    "RESPONSE_PROMPT = (\n",
    "    \"You are an expert on the topic: {research_topic}. Provide an extensive, detailed, and comprehensive answer \"\n",
    "    \"to the research question. In your answer, highlight any areas or gaps that might require further exploration.\"\n",
    ")\n",
    "\n",
    "FIND_GAP_PROMPT = (\n",
    "    \"You are a group of 3 experts on the topic: {research_topic}. \"\n",
    "    \"Think step by step on the following assay: \"\n",
    "    \"<ASSAY>\\n{assay}\\n</ASSAY> \"\n",
    "    \"Provide one new topic to explore to fill a knowledge gap in the assay. \"\n",
    "    \"Based on the gaps identified in your answer, generate a JSON object with the following keys:\\n\"\n",
    "    '   - \"query\": \"The search query string.\"\\n'\n",
    "    '   - \"web-query\": \"The web search query string.\"\\n'\n",
    "    '   - \"aspect\": \"The aspect of the topic being addressed by this query.\"\\n'\n",
    "    '   - \"rationale\": \"Why this query will help fill the gap.\"\\n'\n",
    "    \"Provide only the JSON structure.\"\n",
    ")\n",
    "\n",
    "COMBINE_PROMPT = (\n",
    "    \"You are a group of 3 experts on the topic: {research_topic}. \"\n",
    "    \"You have to combine together the information from the written assay in <ASSAY></ASSAY> tags, \"\n",
    "    \"with the information gathered from the results of a web search on peer-reviewed literature within the <WEB></WEB> tags. \"\n",
    "    \"When combining them together you are allowed to use only the sources identified through the web search. \"\n",
    "    \"Cite them in the text where appropriate and report them at the bottom. \"\n",
    "    \"<ASSAY>\\n{assay}\\n</ASSAY> \"\n",
    "    \"<WEB>\\n{web_search}\\n</WEB>\"\n",
    ")\n",
    "\n",
    "FINALIZE_RESPONSE_PROMPT = (\n",
    "    \"You are a team of experts on the topic: {research_topic}. Your goal is to analyze the text provided in the <TEXT></TEXT> tags \"\n",
    "    \"and create an extensive, detailed, and comprehensive report using the information provided. Aim to 500 words per section. \"\n",
    "    \"Your thesis is formatted in markdown and includes:\\n\"\n",
    "    \"1. Title\\n\"\n",
    "    \"2. Introduction\\n\"\n",
    "    \"3. Discussion\\n\"\n",
    "    \"4. Gaps / Further research\\n\"\n",
    "    \"<TEXT>\\n{notes}\\n</TEXT>\"\n",
    ")\n",
    "\n",
    "# --- Helper: Exponential Backoff for DuckDuckGo Search ---\n",
    "def duckduckgo_search(query: str, max_results: int = 5, fetch_full_page: bool = False, retries: int = 5, backoff: int = 3) -> dict:\n",
    "    \"\"\"\n",
    "    Perform a DuckDuckGo search for the given query with exponential backoff in case of rate limiting.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query.\n",
    "        max_results (int): Number of results to return.\n",
    "        fetch_full_page (bool): If True, attempt to retrieve full page content.\n",
    "        retries (int): Maximum number of retry attempts.\n",
    "        backoff (int): Base backoff delay in seconds.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary with a \"results\" key containing a list of result dicts.\n",
    "    \n",
    "    Raises:\n",
    "        Exception if maximum retries are exceeded.\n",
    "    \"\"\"\n",
    "    from duckduckgo_search import DDGS\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            results = []\n",
    "            with DDGS() as ddgs:\n",
    "                search_results = list(ddgs.text(query, max_results=max_results))\n",
    "                for r in search_results:\n",
    "                    url = r.get(\"href\")\n",
    "                    title = r.get(\"title\")\n",
    "                    content = r.get(\"body\")\n",
    "                    if not all([url, title, content]):\n",
    "                        continue\n",
    "                    raw_content = content\n",
    "                    if fetch_full_page:\n",
    "                        try:\n",
    "                            req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "                            response = urllib.request.urlopen(req)\n",
    "                            html = response.read().decode('utf-8', errors='replace')\n",
    "                            raw_content = BeautifulSoup(html, 'html.parser').get_text()\n",
    "                        except Exception as e:\n",
    "                            raw_content = content  # fallback to snippet content\n",
    "                    results.append({\n",
    "                        \"title\": title,\n",
    "                        \"url\": url,\n",
    "                        \"content\": content,\n",
    "                        \"raw_content\": raw_content\n",
    "                    })\n",
    "            return {\"results\": results}\n",
    "        except Exception as e:\n",
    "            if \"Ratelimit\" in str(e):\n",
    "                wait_time = backoff ** (attempt + 1)\n",
    "                print(f\"Rate limit encountered. Retrying in {wait_time} seconds... (Attempt {attempt+1} of {retries})\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                raise e\n",
    "    raise Exception(\"Exceeded maximum retries due to rate limiting.\")\n",
    "\n",
    "def enhance_query_for_scientific_literature(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Enhance an LLM-generated query to focus on scientific literature by appending \n",
    "    academic-specific filters and keywords.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The original query.\n",
    "        \n",
    "    Returns:\n",
    "        str: The enhanced query.\n",
    "    \"\"\"\n",
    "    filters = \"site:pubmed.ncbi.nlm.nih.gov OR site:sciencedirect.com OR site:doi.org peer-reviewed journal\"\n",
    "    return f\"{query} {filters}\"\n",
    "\n",
    "def search_scientific_literature(query: str, num_results: int = 5, fetch_full_page: bool = False) -> dict:\n",
    "    \"\"\"\n",
    "    Enhance the given query for scientific literature and perform a DuckDuckGo search.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The original query.\n",
    "        num_results (int): Number of results to return.\n",
    "        fetch_full_page (bool): If True, fetch full page content.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Search results as returned by duckduckgo_search.\n",
    "    \"\"\"\n",
    "    enhanced_query = enhance_query_for_scientific_literature(query)\n",
    "    print(\"Enhanced Query:\", enhanced_query)\n",
    "    return duckduckgo_search(enhanced_query, max_results=num_results, fetch_full_page=fetch_full_page)\n",
    "\n",
    "# --- Helper: Remove <THINK> Tags ---\n",
    "def remove_think_tags(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove any text enclosed in <THINK>...</THINK> tags.\n",
    "    The regex is case-insensitive.\n",
    "    \"\"\"\n",
    "    return re.sub(r\"<\\s*THINK\\s*>.*?<\\s*/\\s*THINK\\s*>\", \"\", text, flags=re.DOTALL | re.IGNORECASE).strip()\n",
    "\n",
    "# --- Configuration & State Management ---\n",
    "class Configuration:\n",
    "    def __init__(self, ollama_base_url: str, local_llm: str, fetch_full_page: bool,\n",
    "                 max_research_loops: int, max_fetch_pages: int, max_token_per_search: int):\n",
    "        self.ollama_base_url = ollama_base_url\n",
    "        self.local_llm = local_llm\n",
    "        self.fetch_full_page = fetch_full_page\n",
    "        self.max_research_loops = max_research_loops\n",
    "        self.max_fetch_pages = max_fetch_pages\n",
    "        self.max_token_per_search = max_token_per_search\n",
    "\n",
    "def initialize_state(research_topic: str) -> dict:\n",
    "    \"\"\"\n",
    "    Initialize the research state with the given topic.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"research_topic\": research_topic,\n",
    "        \"initial_response\": \"\",       # The original extensive answer.\n",
    "        \"assay\": \"\",                  # To hold the current assay.\n",
    "        \"search_query\": research_topic\n",
    "    }\n",
    "\n",
    "def query_local_llm(state: dict, config: Configuration, prompt=\"\") -> str:\n",
    "    \"\"\"\n",
    "    Generate an answer for the research topic using the local LLM.\n",
    "    The answer should also indicate potential gaps.\n",
    "    \"\"\"\n",
    "    message = {\"role\": \"user\", \"content\": prompt}\n",
    "    response: ChatResponse = chat(model=config.local_llm, messages=[message])\n",
    "    output = remove_think_tags(response.message.content.strip())\n",
    "    state[\"initial_response\"] = output  # For initial response\n",
    "    state[\"assay\"] = output             # Initialize assay with the output\n",
    "    return output\n",
    "\n",
    "def extract_json_from_llm_output(text: str):\n",
    "    \"\"\"\n",
    "    Attempt to extract a JSON object from the provided text.\n",
    "    Supports:\n",
    "      1. JSON enclosed in triple backticks with tag \"json\".\n",
    "      2. JSON enclosed in triple backticks without tag.\n",
    "      3. A plain JSON string.\n",
    "    \n",
    "    Returns:\n",
    "        Parsed JSON object.\n",
    "        \n",
    "    Raises:\n",
    "        ValueError if no valid JSON structure is found.\n",
    "    \"\"\"\n",
    "    patterns = [\n",
    "        r\"```json\\s*(\\{.*?\\})\\s*```\",  # with \"json\" tag\n",
    "        r\"```(\\{.*?\\})```\"             # without tag\n",
    "    ]\n",
    "    matches = []\n",
    "    for pattern in patterns:\n",
    "        found = re.findall(pattern, text, flags=re.DOTALL | re.IGNORECASE)\n",
    "        if found:\n",
    "            matches.extend(found)\n",
    "    if not matches:\n",
    "        stripped = text.strip()\n",
    "        if stripped.startswith(\"{\") and stripped.endswith(\"}\"):\n",
    "            matches.append(stripped)\n",
    "    if not matches:\n",
    "        print(\"<ERROR>:\\n%s\\n</ERROR>\" % text)\n",
    "        raise ValueError(\"No JSON structure found in the provided text.\")\n",
    "    for match in matches:\n",
    "        try:\n",
    "            json_data = json.loads(match)\n",
    "            return json_data\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "    print(\"<ERROR>:\\n%s\\n</ERROR>\" % text)\n",
    "    raise ValueError(\"Found JSON-like structure, but could not parse it.\")\n",
    "\n",
    "# --- Main Research Pipeline ---\n",
    "def main():\n",
    "    config = Configuration(\n",
    "        ollama_base_url=\"http://localhost:11434\",  # Your Ollama URL\n",
    "        local_llm=\"llama3.2\",                      # Default LLM is \"llama3.2\"\n",
    "        fetch_full_page=True,                      # Fetch full page content if needed\n",
    "        max_research_loops=3,                      # Number of research iterations\n",
    "        max_fetch_pages=5,                         # Number of pages to fetch per search\n",
    "        max_token_per_search=4000                  # Token limit per search processing\n",
    "    )\n",
    "\n",
    "    # Step 1: Get the research question from the user.\n",
    "    research_topic = input(\"Enter your research question: \")\n",
    "    print(\"#### Research Question ####\\n\")\n",
    "    print(research_topic)\n",
    "    print(\"\\n\")\n",
    "    state = initialize_state(research_topic)\n",
    "\n",
    "    # Step 2: Generate an initial explanation (assay) using the local LLM.\n",
    "    print(\"  >> Create initial assay...\\n\")\n",
    "    prompt_initial = RESPONSE_PROMPT.format(research_topic=state[\"research_topic\"])\n",
    "    initial_explanation = query_local_llm(state, config, prompt_initial)\n",
    "    print(initial_explanation)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"#### Thinking Process ####\\n\")\n",
    "    for i in range(config.max_research_loops):\n",
    "        print(f\">> Iteration {i+1}\\n\")\n",
    "        print(\"  >> Find gap...\")\n",
    "        # Step 3: Evaluate the current assay and generate a follow-up question.\n",
    "        prompt_gap = FIND_GAP_PROMPT.format(research_topic=state[\"research_topic\"], assay=state[\"assay\"])\n",
    "        followup_question_llm = query_local_llm(state, config, prompt_gap)\n",
    "        followup_question_json = extract_json_from_llm_output(followup_question_llm)\n",
    "        print(f\"     > Follow-up Question: {followup_question_json['query']}\")\n",
    "        print(f\"     > Web-search query: {followup_question_json['web-query']}\")\n",
    "\n",
    "        # Step 4: Gather literature sources.\n",
    "        print(\"  >> Query web-literature...\")\n",
    "        user_query = followup_question_json[\"web-query\"]\n",
    "        web_search = search_scientific_literature(user_query, num_results=5, fetch_full_page=True)\n",
    "        \n",
    "        # Step 5: Combine literature with the assay.\n",
    "        print(\"  >> Combine literature to assay...\")\n",
    "        prompt_follow = COMBINE_PROMPT.format(research_topic=followup_question_json[\"query\"], assay=state[\"assay\"], web_search=web_search)\n",
    "        follow_explanation = query_local_llm(state, config, prompt_follow)\n",
    "        print(follow_explanation)\n",
    "        # Update the assay by appending the new follow explanation.\n",
    "        state[\"assay\"] = state[\"assay\"] + follow_explanation\n",
    "\n",
    "    # Step 6: Finalize the assay.\n",
    "    prompt_finalize = FINALIZE_RESPONSE_PROMPT.format(research_topic=state[\"research_topic\"], notes=state[\"assay\"])\n",
    "    finalize_text_llm = query_local_llm(state, config, prompt_finalize)\n",
    "    \n",
    "    print(\"#### Final Assay ####\\n\")\n",
    "    display(Markdown(finalize_text_llm))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
